# -*- coding: utf-8 -*-
"""predict_risk.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19_8w9gOnnplXZwqoaE1J7UvbOYjyd7kp
"""

#PROJET RISK DATA MASTERS
#REALISATION : GROUPE 5
#LE GROUPE EST COMPOSE DES MEMBRES CI DESSOUS:

                  #ADJANOHOUN BRAYANN
                  #ADOUSSINGANDE CELINE
                  #COMLAN YAYRA
                  #KOUKPONOU SONAGNON

pip install pymongo

pip install pymysql

import pymongo
import pymysql
import pandas as pd

# NOUS DECLINONS CI-DESSOUS LES DIFFERENTES ETAPES POUR L'IMPORTATION DE LA BASE MONGODB

from pymongo import MongoClient
# Définition des Paramètres de connexion
server = '208.87.130.253:27017'
database = 'mag1_project'
auth_db = 'mag1_project'
collection = 'project'
username = 'mag1_student'
password = 'Gogo1gogo2'

# Connexion à la base de données
client = MongoClient(f"mongodb://{username}:{password}@{server}/{database}?authSource={auth_db}")

# Accès à la collection
db = client[database]
project_collection = db[collection]
mongo_data= list(project_collection.find())
print(mongo_data)

# NOUS DECLINONS CI DESSOUS LES DIFFERENTES ETAPES POUR L'IMPORTATION DE LA BASE MySQL
# Se connecter à MySQL
mysql_connection = pymysql.connect(host="144.24.194.65", port=3999, user="mag1_student",
                                   passwd="Gogo1gogo2", db="mag1_project")

# Récupérer les données de la table "project"
mysql_query = "SELECT * FROM project"
mysql_data = pd.read_sql(mysql_query, mysql_connection)

#Fermer la connexion à MySQL
mysql_connection.close()
#Affichage des colonnes de la base
print(mysql_data.columns)

# NOUS DECLINONS CI DESSOUS LES DIFFERENTES ETAPES POUR L'IMPORTATION DE LA BASE HTML

# Récupérer les données de la table HTML
html_url = "https://h.chifu.eu/data.html"
html_data = pd.read_html(html_url)[0]
# Créer un DataFrame pour chaque jeu de données
mongo_df = pd.DataFrame(mongo_data)
mysql_df = mysql_data
html_df = html_data

# Concaténer les DataFrames
merged_data = pd.merge(mysql_df, html_df, on='Company ID', how='inner')
merged_data = pd.merge(merged_data, pd.DataFrame(list(project_collection.find())), on='Company ID', how='inner')
print(merged_data)

# Enregistrement des données fusionnées dans un fichier CSV
merged_data.to_csv("merged_data.csv", index=False)
print(merged_data)

#DATA MANAGEMENT : MISE EN FORME DES DONNES

data = pd.read_csv("merged_data.csv") #Charger le jeu de données
print(data.head())#Afficher les premières lignes du jeu de données pour avoir un aperçu

print(data ["Credit Rating"])

#TRAVAILLONS LA VARIABLE CREDIT RATING

# Créer une fonction de conversion des modalités en entiers
def convert_rating_to_int(rating):
    ratings_dict = {'A': 9, 'AA': 8, 'AAA': 7, 'B': 6, 'BB': 5, 'BBB': 4, 'C': 3, 'CC': 2, 'CCC': 1}
    return ratings_dict.get(rating)

# Appliquer la fonction de conversion à la colonne "Credit Rating"
data['Credit Rating'] = data['Credit Rating'].map(convert_rating_to_int)

# Calcul des fréquences et affichage
frequences = data['Credit Rating'].value_counts()
print(frequences)

print(data ["Credit Rating"])

print(data.info())#Analyser les informations générales sur les données

print(data.isnull().sum())#Vérifier s'il y a des données manquantes

#sortir la colonne _id pour avoir une seule clée primaire

"""###Analyse descriptive et sélection des variables pertinentes"""

#ANALYSE DESCRIPTIVE DES DONNEES MISE EN FORME : Effectuons une analyse exploratoire des données pour comprendre
# les caractéristiques de notre jeu de données.


# Importez les bibliothèques nécessaires
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

#Résumé statistique des variables numériques
print(data.describe())

print(data['Risk'].describe())

#Distribution de la variable cible
sns.histplot(data=data, x='Risk', kde=True)
plt.show()

#Relation entre la variable cible et les variables explicatives
sns.pairplot(data=data, vars=['Expenses', 'Research and Development Spend','Profit','Debt-to-Equity Ratio','Price-to-Earnings Ratio','Market Capitalization', 'Revenue','Employee Count','Credit Rating','Risk'])
plt.show()

#Test de corrélation pour voir les variables qui sont beaucpup plus corrélées à la variable 'Risk'
corr_matrix = data.corr()
sns.heatmap(corr_matrix, annot=True)
plt.show()


#D'après ce test de corrélation, les variables qui sont fortement correlées à la variable Risk sont:
# + Employee Count
# + Market Capitalisation
# + Price-to-Earnings Ratio
# + Profit

"""###Entrainement"""

#CREATION ET ENTRAINEMENT DU MODELE

#Importation des bibliothèques nécéssaires
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

# Spécification des variables d'entraînement(variables explicatives) et de la variable cible(variable dépendante)
features = ['Expenses', 'Research and Development Spend','Profit','Debt-to-Equity Ratio','Price-to-Earnings Ratio','Market Capitalization', 'Revenue','Employee Count', 'Credit Rating'] # Spécifiez les noms des colonnes qui sont des variables d'entraînement
target = 'Risk' # Spécifiez le nom de la colonne qui est la variable cible

#Division de la base compilée en partie d'entrainement(ajuster le modèle aux données) et une seconde partie test
X_train, X_test, y_train, y_test = train_test_split(data[features], data[target], test_size=0.2, random_state=42)

# Créons le modèle randomForest
decision_tree_model = RandomForestClassifier()

#Entrainons le modèle randomForest
decision_tree_model.fit(X_train, y_train)

#Toujours dans l'optique d'avoir un modèle performant,
#extrayons les importances des variables. i.e celles qui contribuent mieux à la prédiction de'Risk',
#ceci est fait en complément au test de correlation que nous avons fait ci dessus.

feature_names = ['Expenses', 'Research and Development Spend','Profit','Debt-to-Equity Ratio','Price-to-Earnings Ratio','Market Capitalization', 'Revenue','Employee Count', 'Credit Rating']
for i in range(len(decision_tree_model.feature_importances_)):
    print(f"{feature_names[i]} : {decision_tree_model.feature_importances_[i]}")

#Les variables importantes sont(faire le lien avec la corrélation)
#on adate le modèle à ces variables qui ont des poids importants pour une meilleure précision
#+ Employee Count
#+ Debt-to-Equity Ratio
#+ Profit
#+ Price-to-Earnings Ratio
#+ Market Capitalization

"""###Ici je fais les simulations avec les variables"""

#Modèle amélioré en tenant compte de l'importance des variables
# Spécifier les variables d'entraînement et la variable cible à nouveau

features = ['Debt-to-Equity Ratio','Market Capitalization','Profit','Employee Count'] # Spécifiez les noms des colonnes qui sont des variables d'entraînement
target = 'Risk' # Spécifiez le nom de la colonne qui est la variable cible

# Diviser les données en ensembles d'entraînement et de test
X_train, X_test, y_train, y_test = train_test_split(data[features], data[target], test_size=0.2, random_state=42)

# Créer et entraîner le modèle randomForest
from sklearn.ensemble import RandomForestClassifier
decision_tree_model = RandomForestClassifier()
decision_tree_model.fit(X_train, y_train)

feature_names =['Market Capitalization','Profit','Employee Count','Debt-to-Equity Ratio']
for i in range(len(decision_tree_model.feature_importances_)):
    print(f"{feature_names[i]} : {decision_tree_model.feature_importances_[i]}")

# Faire des prédictions sur les données de test
y_pred = decision_tree_model.predict(X_test)

# Evaluer les performances du modèle
accuracy = accuracy_score(y_test,y_pred )
print("Accuracy: ", accuracy)

#RAPPORT DE CLASSIFICATION

from sklearn.metrics import classification_report

# générer le rapport de classification
report = classification_report(y_test, y_pred)

# afficher le rapport de classification à l'écran
print(report)

#EFFECTUONS LES PREDICTIONS SUR LES DONNES DE TEST

# Charger les données de test
test_url = 'https://h.chifu.eu/final_test.csv'
test_df = pd.read_csv(test_url)
print(test_df.head())#Afficher les premières lignes du jeu de données pour avoir un aperçu

# Prétraiter les données de test(data management sur test)

print(test_df.info())#Analyser les informations générales sur les données

print(test_df.isnull().sum())#Vérifier s'il y a des données manquantes

#On doit travailler Credit Rating mais comme on a pas utiliser cela
#dans notre modèle final nous pensons qu'on peut laisser

#UTILISER MAINTENANT NOTRE MODELE ENTRAINER ET DONT LES METRIQUES ONT ETE EVALUER POUR PREDIRE LA VARIABLE RISK,
#DANS CE DATAFRAME QUI NE CONTIENT QUE DES FEATURES

# Faire des prédictions sur les données de test
test_predictions = decision_tree_model2.predict(test_df[features2])

# Afficher les prédictions
print(test_predictions)

import csv

# Nom du fichier CSV à créer

CompanyID= test_df['Company ID']

# Créer un fichier CSV
with open('predictions.csv', 'w', newline='') as csvfile:
    writer = csv.writer(csvfile)

    # Écrire l'en-tête
    writer.writerow(['Company ID', 'test predictions'])

    # Écrire les données
    for i in range(len(CompanyID)):
        writer.writerow([CompanyID[i], test_predictions[i]])

# Afficher le contenu du fichier CSV
with open('predictions.csv', 'r') as csvfile:
    reader = csv.reader(csvfile)

    for row in reader:
        print(row)

pip install argparse

#Votre script doit accepter le fichier de sortie en tant qu'argument en utilisant le module

import argparse

# Paramétrer les arguments en ligne de commande
parser = argparse.ArgumentParser()

args = parser.parse_args()

# Nom du fichier CSV à créer
CompanyID = test_df['Company ID']
test_predictions = ...

# Créer un fichier CSV avec le nom spécifié en argument
with open(args.output, 'w', newline='') as csvfile:
    writer = csv.writer(csvfile)

    # Écrire l'en-tête
    writer.writerow(['Company ID', 'test predictions'])

    # Écrire les données
    for i in range(len(CompanyID)):
        writer.writerow([CompanyID[i], test_predictions[i]])

# Afficher le contenu du fichier CSV
with open(args.output, 'r') as csvfile:
    reader = csv.reader(csvfile)

    for row in reader:
        print(row)

#RECUPERATION DU FICHIER REQUIREMENTS(Les packages qui ont permis de faire le travail)

import os

# Récupérer le répertoire actuel
current_directory = os.path.dirname(os.path.abspath('requirements.txt'))

# Générer le chemin source du fichier requirements.txt
requirements_path = os.path.join(current_directory, 'requirements.txt')

print(requirements_path)

/content/requirements.txt